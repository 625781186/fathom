

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Training &mdash; Fathom 3.4.1 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/tweaks.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Rule and Ruleset Reference" href="ruleset.html" />
    <link rel="prev" title="Basic Use" href="using.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> Fathom
          

          
          </a>

          
            
            
              <div class="version">
                3.4.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="intro.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="using.html">Basic Use</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Training</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#collecting-samples">Collecting Samples</a></li>
<li class="toctree-l2"><a class="reference internal" href="#designing-rules">Designing Rules</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#sources-of-signal">Sources of Signal</a></li>
<li class="toctree-l3"><a class="reference internal" href="#rules-of-thumb">Rules of Thumb</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#suggested-directory-structure">Suggested Directory Structure</a></li>
<li class="toctree-l2"><a class="reference internal" href="#installing-fathom-s-commandline-tools">Installing Fathom’s Commandline Tools</a></li>
<li class="toctree-l2"><a class="reference internal" href="#storing-large-corpora-in-version-control">Storing Large Corpora in Version Control</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#using-fathom-extract">Using fathom-extract</a></li>
<li class="toctree-l3"><a class="reference internal" href="#configuring-git-lfs">Configuring Git-LFS</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#running-the-trainer">Running the Trainer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#workflow">Workflow</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="ruleset.html">Rule and Ruleset Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="clustering.html">Clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="fnodes.html">Fnode Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="utilities.html">Utility Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="zoo.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="development.html">Development</a></li>
<li class="toctree-l1"><a class="reference internal" href="versions.html">Version History</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="glossary.html">Glossary</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Fathom</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Training</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/training.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="training">
<h1>Training<a class="headerlink" href="#training" title="Permalink to this headline">¶</a></h1>
<p>Training is the process by which Fathom combines your handwritten rules with your labeled example pages to create the most accurate possible model. Training emits a set of numerical parameters:</p>
<ul class="simple">
<li><p>One <em>coefficient</em> per rule, which indicates the rule’s relative weight</p></li>
<li><p>One <em>bias</em> per type, which centers element’s scores so they can be construed as 0..1 confidences</p></li>
</ul>
<div class="section" id="collecting-samples">
<h2>Collecting Samples<a class="headerlink" href="#collecting-samples" title="Permalink to this headline">¶</a></h2>
<p>Use <a class="reference external" href="https://addons.mozilla.org/en-US/firefox/addon/fathomfox/">FathomFox</a> to collect samples. It has both a bulk collector and a page-at-a-time method integrated into Firefox’s developer tools. Typically, you’ll use the latter. See the documentation on the aforementioned page for details.</p>
<p>The pages serialized by FathomFox will be large, on the order of 100-200MB each. So far, the best organizational approach we’ve found is to check them into git, along with your application and a <code class="docutils literal notranslate"><span class="pre">rulesets.js</span></code> file you create to hold your rulesets. The <strong class="command">fathom-extract</strong> tool makes this feasible; see <a class="reference internal" href="#storing-large-corpora-in-version-control">Storing Large Corpora in Version Control</a>.</p>
<p>So far, a training set on the order of a few hundred samples has been sufficient to push validation accuracy above 99%. You’ll want additional samples for a validation set (to let the trainer know when it’s begun to overfit) and a test set (to come up with final accuracy numbers). We recommend a 60/20/20 split among training/validation/testing set. This gives you large enough validation and testing sets, at typical corpus sizes, while shunting as many samples as possible to the training set so you can mine them for rule ideas.</p>
<p>It’s important to keep your sets mutually representative. If you have a bunch of samples sorted by some metric, like site popularity or when they were collected, don’t use samples 1-100 for training and then 101-200 for validation. Instead, collect a set of samples, and then use <strong class="command">fathom-pick</strong> to proportionally assign them to sets: 60% to training and 20% to each of validation and testing. You can repeat this as you later come to need more samples.</p>
</div>
<div class="section" id="designing-rules">
<h2>Designing Rules<a class="headerlink" href="#designing-rules" title="Permalink to this headline">¶</a></h2>
<p>Each rule should generally express one machine-learning feature—or “smell”, to coin a metaphor. The score it applies—the return value of the callback passed to <a class="reference internal" href="ruleset.html#score" title="score"><code class="xref js js-func docutils literal notranslate"><span class="pre">score()</span></code></a>—should be a number from 0 to 1, inclusive, representing the probability that that smell is present. These smells are later balanced by the trainer.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For many smells, it’s natural to return hard 0s or 1s (or trues and falses, if that’s more convenient). If you have fuzzier values to return—as from a rule that expresses something subjectively defined like “image is big”—<a class="reference internal" href="utilities.html#linearScale" title="linearScale"><code class="xref js js-func docutils literal notranslate"><span class="pre">linearScale()</span></code></a> and <a class="reference internal" href="utilities.html#sigmoid" title="sigmoid"><code class="xref js js-func docutils literal notranslate"><span class="pre">sigmoid()</span></code></a> will help you clamp down extreme values. Make the choice based on whether two adjacent extreme values should still have distinguishable outputs. If they should, go with sigmoid().</p>
</div>
<div class="section" id="sources-of-signal">
<h3>Sources of Signal<a class="headerlink" href="#sources-of-signal" title="Permalink to this headline">¶</a></h3>
<p>What sorts of rules should you write? In short, ones that express simple, atomic smells that tend to be found in—or lacked by—target elements. For example, if you are trying to recognize the images of products for sale on shopping sites, the target image might have smells like…</p>
<ul class="simple">
<li><p>Large size</p></li>
<li><p>Position near the top of the page</p></li>
<li><p>Position near the left of the page</p></li>
<li><p>IDs or class names that contain the strings “hero” or “product”</p></li>
</ul>
<p>Don’t worry about expressing boolean combinations of smells except as a last resort. It’s generally sufficient to let Fathom optimize a linear combination of them. Also, Fathom will determine on its own whether to give a positive or negative weight to a smell; you don’t need to tell it.</p>
<p>Since the primitives exposed by Fathom are thus far geared to the measurement of DOM properties (rather than, say, natural language processing), the best bang for your buck is generally rules that consider…</p>
<ul class="simple">
<li><p>CSS classes and IDs. Begin by simply testing for inclusion of signal-bearing strings. It is probably unnecessary to apply tokenization.</p></li>
<li><p>Rendered size or position of elements</p></li>
<li><p>Alignment or proximity of elements to each other. So far, the state of the art is to program a bit of “look around” into the scoring callback. It is also possible to get ahold of the <a class="reference internal" href="ruleset.html#BoundRuleset" title="BoundRuleset"><code class="xref js js-class docutils literal notranslate"><span class="pre">BoundRuleset()</span></code></a> object and try to pair up the examined node with another of a certain type, but so far it’s a manual process.</p></li>
<li><p>Font sizes</p></li>
<li><p>Colors and borders</p></li>
<li><p>Visibility</p></li>
<li><p>Any of the above in <a class="reference internal" href="utilities.html#ancestors" title="ancestors"><code class="xref js js-func docutils literal notranslate"><span class="pre">ancestor</span></code></a> elements of the target</p></li>
</ul>
<p>A useful technique is to look at some of the pages in your corpus and blur your eyes slightly. This shows you the page as Fathom sees it: you can’t read the text, but you can likely still recognize the target elements. Write rules that express the smells you are using to do so.</p>
<p>Computed CSS properties are worth a special mention: <a class="reference external" href="https://developer.mozilla.org/en-US/docs/Web/API/Window/getComputedStyle">getComputedStyle()</a> is the most robust way to retrieve style information about an element, since most properties are inherited through the complex interplay of stylesheets. Don’t try to look at <code class="docutils literal notranslate"><span class="pre">style</span></code> attributes directly or otherwise painstakingly reason out styles.</p>
</div>
<div class="section" id="rules-of-thumb">
<h3>Rules of Thumb<a class="headerlink" href="#rules-of-thumb" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Lots of simple rules are better than fewer, more complex ones. Not only are they easier to write, but the further you can break up your guesses into separately optimizable pieces, the more good the trainer can do.</p></li>
<li><p>Your rules don’t all have to be good. If you have an idea for a smell, code it up. If it was a bad idea, the trainer will give it a coefficient near 0, and you can prune it away.</p></li>
<li><p><a class="reference internal" href="ruleset.html#when" title="when"><code class="xref js js-func docutils literal notranslate"><span class="pre">when()</span></code></a> is good for early pruning: hard, yes/no decisions on what should be considered. Scores are for gradations. Pruning makes your vector files smaller and training faster.</p></li>
<li><p>Many good rule ideas come out of labeling samples. If you are not labeling samples yourself, at least study them in depth so you can notice patterns.</p></li>
<li><p>Rubrics are vital for labeling. If samples are labeled inconsistently, they will push the trainer in conflicting directions, and your accuracy will suffer. Also, keep your rubrics up to date. Whenever you encounter a case where you have to make a new decision—something the rubric doesn’t already clearly decide—edit the rubric to codify that decision so you are consistent with it in the future. Check your rubrics into version control.</p></li>
<li><p>Include some samples that are missing the thing you’re trying to recognize so your ruleset learns to avoid false positives. We call these “negative” samples, and they should generally make up 20-50% of your corpus.</p></li>
</ul>
</div>
</div>
<div class="section" id="suggested-directory-structure">
<h2>Suggested Directory Structure<a class="headerlink" href="#suggested-directory-structure" title="Permalink to this headline">¶</a></h2>
<p>We’ve mentioned a number of items to check into version control. Here is a directory structure that works well:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>runs/             -- TensorBoard data emitted by the trainer
samples/
    unused/
        3.html   -- A positive sample, which contains an example of what we&#39;re looking for
        10.html
        14.html
        n4.html  -- A negative sample: one that does NOT contain what we&#39;re looking for
        n7.html
        n11.html
        ...
    training/
        1.html
        n2.html
        5.html
        ...
    validation/
    testing/
    rubric.txt
rulesets.js       -- Ruleset code
vectors/          -- Feature vectors cached by fathom-train and fathom-test
    training_yourTraineeIdHere.json
    validation_yourTraineeIdHere.json
    testing_yourTraineeIdHere.json
</pre></div>
</div>
<p>A few notes:</p>
<ul class="simple">
<li><p>The negative samples’ numerical IDs are in the same namespace as the positive ones, but we prefix them with an n. This is so that, when the trainer says it assumed a sample was negative because it had no labeled target elements, we can tell at a glance whether it was correct.</p></li>
<li><p>Samples start in the <code class="docutils literal notranslate"><span class="pre">unused</span></code> folder. From there, they should be divided among the training, validation, and testing ones using <strong class="command">fathom-pick</strong>, which randomly moves a given number of files from one directory to another to keep the sets mutually representative.</p></li>
</ul>
</div>
<div class="section" id="installing-fathom-s-commandline-tools">
<h2>Installing Fathom’s Commandline Tools<a class="headerlink" href="#installing-fathom-s-commandline-tools" title="Permalink to this headline">¶</a></h2>
<p>Fathom’s commandline tools are Python 3 programs. If you don’t already have Python 3.7 or better, download it from <a class="reference external" href="https://www.python.org/downloads/">https://www.python.org/downloads/</a>. Then, install the Fathom tools by running…</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip3</span> <span class="n">install</span> <span class="n">fathom</span><span class="o">-</span><span class="n">web</span>
</pre></div>
</div>
<p>It’s possible your Python package manager (“pip”) is called simply “pip” rather than “pip3”. Give that a try if the above fails.</p>
</div>
<div class="section" id="storing-large-corpora-in-version-control">
<h2>Storing Large Corpora in Version Control<a class="headerlink" href="#storing-large-corpora-in-version-control" title="Permalink to this headline">¶</a></h2>
<p>Fathom corpora often bump up against the limits imposed by git hosting services like GitHub. Thus, we recommend using <a class="reference external" href="https://git-lfs.github.com/">Git Large File Storage (LFS)</a> to store samples. This is facilitated by a tool called <strong class="command">fathom-extract</strong>, which breaks large subresources like images back out of the HTML. As a bonus, your HTML files will shrink drastically and become feasible to diff.</p>
<div class="section" id="using-fathom-extract">
<h3>Using fathom-extract<a class="headerlink" href="#using-fathom-extract" title="Permalink to this headline">¶</a></h3>
<p><strong class="command">fathom-extract</strong> pulls the inlined data URLs representing subresources (like images and CSS) out of your samples, converts them into images and CSS files, places them in a newly created sample-specific directory within a newly created resources directory, and replaces the data URLs with references to the new files. This let you use Git-LFS to store the new subresource files.</p>
<p>For example, if you have this directory of samples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">samples</span><span class="o">/</span>
    <span class="n">unused</span><span class="o">/</span>
        <span class="mf">3.</span><span class="n">html</span>
        <span class="mf">10.</span><span class="n">html</span>
        <span class="mf">14.</span><span class="n">html</span>
        <span class="o">...</span>
</pre></div>
</div>
<p>Running…</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">fathom</span><span class="o">-</span><span class="n">extract</span> <span class="n">samples</span><span class="o">/</span><span class="n">unused</span>
</pre></div>
</div>
<p>will change your directory to:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">samples</span><span class="o">/</span>
    <span class="n">unused</span><span class="o">/</span>
        <span class="n">originals</span><span class="o">/</span>
        <span class="n">resources</span><span class="o">/</span>
            <span class="mi">3</span><span class="o">/</span>
                <span class="mf">1.</span><span class="n">png</span>
                <span class="mf">2.</span><span class="n">css</span>
                <span class="mf">3.</span><span class="n">css</span>
                <span class="o">...</span>
            <span class="mi">10</span><span class="o">/</span>
                <span class="mf">1.</span><span class="n">css</span>
                <span class="mf">2.</span><span class="n">jpg</span>
                <span class="mf">3.</span><span class="n">jpg</span>
                <span class="o">...</span>
            <span class="mi">14</span><span class="o">/</span>
                <span class="mf">1.</span><span class="n">css</span>
                <span class="mf">2.</span><span class="n">png</span>
                <span class="mf">3.</span><span class="n">jpg</span>
                <span class="o">...</span>
            <span class="o">...</span>
        <span class="mf">3.</span><span class="n">html</span>
        <span class="mf">10.</span><span class="n">html</span>
        <span class="mf">14.</span><span class="n">html</span>
        <span class="o">...</span>
</pre></div>
</div>
<p>Once you are comfortable that your samples extracted correctly, you can delete the <code class="docutils literal notranslate"><span class="pre">originals</span></code> directory.</p>
</div>
<div class="section" id="configuring-git-lfs">
<h3>Configuring Git-LFS<a class="headerlink" href="#configuring-git-lfs" title="Permalink to this headline">¶</a></h3>
<p>With your extracted samples directory, you can follow the <a class="reference external" href="https://git-lfs.github.com/">Git-LFS Getting Started steps</a> to track your new resources directory. In step 2, instead of running the <code class="docutils literal notranslate"><span class="pre">git</span> <span class="pre">lfs</span> <span class="pre">track</span></code> command, you may find it easier to directly edit the <code class="docutils literal notranslate"><span class="pre">.gitattributes</span></code> file. For our resources directory, you would add the line:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">samples</span><span class="o">/**/</span><span class="n">resources</span><span class="o">/**</span> <span class="nb">filter</span><span class="o">=</span><span class="n">lfs</span> <span class="n">diff</span><span class="o">=</span><span class="n">lfs</span> <span class="n">merge</span><span class="o">=</span><span class="n">lfs</span> <span class="o">-</span><span class="n">text</span>
</pre></div>
</div>
<p>The first <code class="docutils literal notranslate"><span class="pre">/**</span></code> ensures all sample directories (<code class="docutils literal notranslate"><span class="pre">unused</span></code>, <code class="docutils literal notranslate"><span class="pre">training</span></code>, etc.) are tracked, and the second <code class="docutils literal notranslate"><span class="pre">/**</span></code> ensures the subdirectories are tracked.</p>
</div>
</div>
<div class="section" id="running-the-trainer">
<h2>Running the Trainer<a class="headerlink" href="#running-the-trainer" title="Permalink to this headline">¶</a></h2>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Fathom has had several trainers over its evolution. Both the Corpus Framework and the trainer built into old versions of FathomFox are obsoleted by <strong class="command">fathom-train</strong>, described herein.</p>
</div>
<p>Once your samples are collected and at least several rules are written, you’re ready to do some initial training. Training is done for one type at a time. If you have types that depend on other types (an advanced case), train the other types first.</p>
<p>Run the trainer. A simple beginning, using just a training set, is…</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">fathom</span><span class="o">-</span><span class="n">train</span> <span class="n">samples</span><span class="o">/</span><span class="n">training</span> <span class="o">--</span><span class="n">ruleset</span> <span class="n">rulesets</span><span class="o">.</span><span class="n">js</span> <span class="o">--</span><span class="n">trainee</span> <span class="n">yourTraineeId</span>
</pre></div>
</div>
<p>…yielding something like…</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>{&quot;coeffs&quot;: [
        [&#39;nextAnchorIsJavaScript&#39;, 1.1627885103225708],
        [&#39;nextButtonTypeSubmit&#39;, 4.613410949707031],
        [&#39;nextInputTypeSubmit&#39;, 4.374269008636475],
        [&#39;nextInputTypeImage&#39;, 6.867544174194336],
        [&#39;nextLoginAttrs&#39;, 0.07278082519769669],
        [&#39;nextButtonContentContainsLogIn&#39;, -0.6560719609260559],
        ],
     &quot;bias&quot;: -3.9029786586761475}

Training precision: 0.9834   Recall: 1.0000                           Predicted
          Accuracy: 0.9889   95% CI: (0.9780, 0.9997)        ╭───┬── + ───┬── - ───╮
               FPR: 0.0328   95% CI: (0.0012, 0.0644)   True │ + │    237 │      0 │
               FNR: 0.0000   95% CI: (0.0000, 0.0000)        │ - │      4 │    118 │
          F1 Score: 0.9916                                   ╰───┴────────┴────────╯

Time per page (ms): 2 |▁▃█▅▂▁    | 34    Average per tag: 8

Training per-tag results:
   AR_534.html  &lt;input type=&quot;password&quot; class=&quot;form-control pass&quot; autocomplete=&quot;off&quot; id=&quot;password        1.00000000
   CS_474.html  &lt;input type=&quot;password&quot; data-placeholder=&quot;register.password1&quot; placeholder=&quot;Heslo&quot;        1.00000000
                &lt;input type=&quot;password&quot; data-placeholder=&quot;register.password2&quot; placeholder=&quot;Heslo         1.00000000
   CZ_36n.html  No targets found.
   DA_177.html  &lt;input data-validation-match=&quot;#UserModel_VerifyPassword&quot; id=&quot;UserModel_ActionMod        0.99999964
   ...
</pre></div>
</div>
<p>Viewing the TensorBoard graphs with <code class="docutils literal notranslate"><span class="pre">tensorboard</span> <span class="pre">--logdir</span> <span class="pre">runs/</span></code> will quickly show you whether the loss function is oscillating. If you see oscilloscope-like wiggles rather than a smooth descent, the learning rate is too high: the trainer is taking steps that are too big and overshooting the optimum it’s chasing. Decrease the learning rate by a factor of 10 until the graph becomes monotonically decreasing:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">fathom</span><span class="o">-</span><span class="n">train</span> <span class="n">samples</span><span class="o">/</span><span class="n">training</span>  <span class="o">--</span><span class="n">ruleset</span> <span class="n">rulesets</span><span class="o">.</span><span class="n">js</span> <span class="o">--</span><span class="n">trainee</span> <span class="n">yourTraineeId</span> <span class="o">--</span><span class="n">learning</span><span class="o">-</span><span class="n">rate</span> <span class="mf">0.1</span> <span class="o">-</span><span class="n">c</span> <span class="n">tryingToRemoveOscillations</span>
</pre></div>
</div>
<p>Comments (with <code class="docutils literal notranslate"><span class="pre">-c</span></code>) are your friend, as a heap of anonymous TensorBoard runs otherwise quickly becomes indistinguishable.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Fathom currently uses the <a class="reference external" href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#Adam">Adam</a> optimization algorithm, which is good at tuning its own learning rates. Even if the loss graph oscillates at the start, it will eventually flatten out, given enough iterations. However, it’s best to tamp down oscillations from the beginning so you can use validation-guided early stopping. Adam seems to dial in the learning rate quickly enough, as long as you get it within a power of 10.</p>
<p>Incidentally, it’s not the end of the world if some scores go slightly outside [0, 1]. Limited tests have gotten away with values up to about 10 without measurable harm to training speed or accuracy. However, when feature values differ in magnitude by a factor of 1000, annoying oscillations dominate early iterations. Stick to [0, 1] for a trouble-free experience.</p>
</div>
<p>Once you’ve tamped down oscillations, use validation samples and early stopping to keep Fathom from overfitting:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">fathom</span><span class="o">-</span><span class="n">train</span> <span class="n">samples</span><span class="o">/</span><span class="n">training</span> <span class="o">--</span><span class="n">ruleset</span> <span class="n">rulesets</span><span class="o">.</span><span class="n">js</span> <span class="o">--</span><span class="n">trainee</span> <span class="n">yourTraineeId</span> <span class="o">--</span><span class="n">validation</span><span class="o">-</span><span class="nb">set</span> <span class="n">samples</span><span class="o">/</span><span class="n">validaton</span> <span class="o">--</span><span class="n">stop</span><span class="o">-</span><span class="n">early</span> <span class="o">-</span><span class="n">c</span> <span class="n">tryingEarlyStopping</span>
</pre></div>
</div>
<p>The trainer comes with a variety of adjustment knobs to ensure a good fit and a good tradeoff between false positives and false negatives. Here is its online help, to give you a sense of its full capabilities:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>% fathom-train --help

Usage: fathom-train [OPTIONS] TRAINING_SET_FOLDER

  Compute optimal numerical parameters for a Fathom ruleset.

  There are a lot of options, but the usual invocation is something like...

    fathom-train samples/training --validation-set samples/validation
    --stop-early --ruleset rulesets.js --trainee new

  TRAINING_SET_FOLDER is a directory of labeled training pages. It can also
  be, for backward compatibility, a JSON file of vectors from FathomFox&#39;s
  Vectorizer.

  To see graphs of the results, install TensorBoard, then run this:
  tensorboard --logdir runs/. These will tell you whether you need to adjust
  the --learning-rate.

  Some vocab used in the output messages:

    target -- A &quot;right answer&quot; DOM node, one that should be recognized

    candidate -- Any node (target or not) brought into the ruleset, by a
    dom() call, for consideration

    negative sample -- A sample with no intended target nodes, used to bait
    the recognizer into a false-positive choice

Options:
  -a, --validation-set FOLDER     Either a folder of validation pages or a
                                  JSON file made manually by FathomFox&#39;s
                                  Vectorizer. Validation pages are used to
                                  avoid overfitting.

  -r, --ruleset FILE              The rulesets.js file containing your rules.
                                  The file must have no imports except from
                                  fathom-web, so pre-bundle if necessary.

  --trainee ID                    The trainee ID of the ruleset you want to
                                  train. Usually, this is the same as the type
                                  you are training for.

  --training-cache FILE           Where to cache training vectors to speed
                                  future training runs. Any existing file will
                                  be overwritten. [default:
                                  vectors/training_yourTraineeId.json next to
                                  your ruleset]

  --validation-cache FILE         Where to cache validation vectors to speed
                                  future training runs. Any existing file will
                                  be overwritten. [default:
                                  vectors/validation_yourTraineeId.json next
                                  to your ruleset]

  --delay INTEGER                 Number of seconds to wait for a page to load
                                  before vectorizing it  [default: 5]

  --show-browser                  Show browser window while vectorizing.
                                  (Browser runs in headless mode by default.)

  -s, --stop-early                Stop 1 iteration before validation loss
                                  begins to rise, to avoid overfitting. Before
                                  using this, check Tensorboard graphs to make
                                  sure validation loss is monotonically
                                  decreasing.

  -l, --learning-rate FLOAT       The learning rate to start from  [default:
                                  1.0]

  -i, --iterations INTEGER        The number of training iterations to run
                                  through  [default: 1000]

  -p, --pos-weight FLOAT          The weighting factor given to all positive
                                  samples by the loss function. See: https://p
                                  ytorch.org/docs/stable/nn.html#bcewithlogits
                                  loss

  -c, --comment TEXT              Additional comment to append to the
                                  Tensorboard run name, for display in the web
                                  UI

  -q, --quiet                     Hide per-tag diagnostics that may help with
                                  ruleset debugging.

  -t, --confidence-threshold FLOAT
                                  Threshold at which a sample is considered
                                  positive. Higher values decrease false
                                  positives and increase false negatives.
                                  [default: 0.5]

  -y, --layer INTEGER             Add a hidden layer of the given size. You
                                  can specify more than one, and they will be
                                  connected in the given order. EXPERIMENTAL.

  -x, --exclude TEXT              Exclude a rule while training. This helps
                                  with before-and-after tests to see if a rule
                                  is effective.

  --help                          Show this message and exit.
</pre></div>
</div>
</div>
<div class="section" id="workflow">
<h2>Workflow<a class="headerlink" href="#workflow" title="Permalink to this headline">¶</a></h2>
<p>A sane authoring process is a feedback loop something like this:</p>
<ol class="arabic simple">
<li><p>Collect samples. Observe patterns in the <a class="reference internal" href="glossary.html#term-target"><span class="xref std std-term">target</span></a> nodes as you do.</p></li>
<li><p>Write a few rules based on your observations.</p></li>
<li><p>Run the trainer. Start with 10-20 training pages and an equal number of validation ones.</p></li>
<li><p>If accuracy is insufficient, examine the failing training pages. The trainer will point these out on the commandline, but FathomFox’s Evaluator will help you track down ones that are hard to distinguish from their tag excerpts. Remediate by changing or adding rules. If there are smells Fathom is missing—positive or negative—add rules that score based on them.</p></li>
<li><p>Go back to step 3.</p></li>
<li><p>Once <em>validation accuracy</em> is sufficient, use the <strong class="command">fathom-test</strong> tool on a fresh set of <em>testing</em> samples. This is your <em>testing accuracy</em> and should reflect real-world performance, assuming your sample size is large and representative enough. The computed 95% confidence intervals should help you decide the former.</p></li>
<li><p>If testing accuracy is too low, imbibe the testing pages into your training set, and go back to step 3. As typical in supervised learning systems, testing samples should be considered “burned” once they are measured against a single time, as otherwise you are effectively training against them. Samples are precious.</p></li>
<li><p>If testing accuracy is sufficient, you’re done! Make sure the latest ruleset and coefficients are in your finished product, and ship it.</p></li>
</ol>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="ruleset.html" class="btn btn-neutral float-right" title="Rule and Ruleset Reference" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="using.html" class="btn btn-neutral float-left" title="Basic Use" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017-2019, Mozilla Foundation

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>